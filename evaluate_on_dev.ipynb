{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b9e31ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shaya\\Desktop\\CS 162 Final Project\\.env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import joblib\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "import torch\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d462e959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes model and vectorizer loaded successfully.\n",
      "Using device: cuda:0 for BERT.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Processing Dev File: ./devset/arxiv_chatGPT.jsonl ---\n",
      "\n",
      "Evaluating NaiveBayes_arxiv_chatGPT...\n",
      "Results for NaiveBayes_arxiv_chatGPT → Acc: 0.5312, Prec: 0.6866, Rec: 0.1147, F1: 0.1965\n",
      "Top 3 NB Misclassified for arxiv_chatGPT:\n",
      "  NB_Err 1: True=AI, Pred=Human, Text='In this paper, we investigate the continuum limit of polymer quantum mechanics. The aim of our work ...'\n",
      "  NB_Err 2: True=AI, Pred=Human, Text='In this work, we present the results of high-resolution spectroscopic observations of the intermedia...'\n",
      "  NB_Err 3: True=AI, Pred=Human, Text='In this work, we present a new method of integrating stochastic differential equations on Lie groups...'\n",
      "\n",
      "Evaluating BERT_arxiv_chatGPT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for BERT_arxiv_chatGPT → Acc: 0.5333, Prec: 0.7128, Rec: 0.1117, F1: 0.1931\n",
      "Top 3 BERT Misclassified for arxiv_chatGPT:\n",
      "  BERT_Err 1: True=AI, Pred=Human, Text='In this paper, we investigate the continuum limit of polymer quantum mechanics. The aim of our work ...'\n",
      "  BERT_Err 2: True=AI, Pred=Human, Text='In this paper, we present the results of our analysis of the Serpens star-forming region using data ...'\n",
      "  BERT_Err 3: True=AI, Pred=Human, Text='In this work, we present the results of high-resolution spectroscopic observations of the intermedia...'\n",
      "\n",
      "\n",
      "--- Processing Dev File: ./devset/arxiv_cohere.jsonl ---\n",
      "\n",
      "Evaluating NaiveBayes_arxiv_cohere...\n",
      "Results for NaiveBayes_arxiv_cohere → Acc: 0.6577, Prec: 0.8754, Rec: 0.3677, F1: 0.5178\n",
      "Top 3 NB Misclassified for arxiv_cohere:\n",
      "  NB_Err 1: True=AI, Pred=Human, Text='\n",
      "We consider a system of many polymers in solution that interact via an external force that is appli...'\n",
      "  NB_Err 2: True=AI, Pred=Human, Text='\n",
      "\n",
      "Spectroscopic Observations of the Intermediate Polar EX Hydrae in Quiescence\n",
      "\n",
      "We present a photome...'\n",
      "  NB_Err 3: True=AI, Pred=Human, Text='\n",
      "\n",
      "ALMA as the ideal probe of the solar chromosphere\n",
      "We present a detailed study of the solar chromos...'\n",
      "\n",
      "Evaluating BERT_arxiv_cohere...\n",
      "Results for BERT_arxiv_cohere → Acc: 0.6475, Prec: 0.8831, Rec: 0.3400, F1: 0.4910\n",
      "Top 3 BERT Misclassified for arxiv_cohere:\n",
      "  BERT_Err 1: True=AI, Pred=Human, Text='\n",
      "\n",
      "We present a catalog of 66 YSOs in the Serpens cloud, as observed with IRAC and MIPS, and discuss ...'\n",
      "  BERT_Err 2: True=AI, Pred=Human, Text='\n",
      "\n",
      "Spectroscopic Observations of the Intermediate Polar EX Hydrae in Quiescence\n",
      "\n",
      "We present a photome...'\n",
      "  BERT_Err 3: True=AI, Pred=Human, Text='\n",
      "\n",
      "We present a new class of stochastic Lie group integrators that is suitable for integration of sto...'\n",
      "\n",
      "\n",
      "--- Processing Dev File: ./devset/reddit_chatGPT.jsonl ---\n",
      "\n",
      "Evaluating NaiveBayes_reddit_chatGPT...\n",
      "Results for NaiveBayes_reddit_chatGPT → Acc: 0.4877, Prec: 0.4829, Rec: 0.3493, F1: 0.4054\n",
      "Top 3 NB Misclassified for reddit_chatGPT:\n",
      "  NB_Err 1: True=AI, Pred=Human, Text='Well, let me tell you, it was quite a tragic event for both Henry II and his opponent Gabriel de Mon...'\n",
      "  NB_Err 2: True=Human, Pred=AI, Text='In 1801, James Monroe and Robert R. Livingston (the R. also stood for Robert, oddly enough) were sen...'\n",
      "  NB_Err 3: True=Human, Pred=AI, Text='Good question! [I answered this a few years back,](_URL_7_) but it was a fun topic so I'll pull that...'\n",
      "\n",
      "Evaluating BERT_reddit_chatGPT...\n",
      "Results for BERT_reddit_chatGPT → Acc: 0.6657, Prec: 0.6833, Rec: 0.6177, F1: 0.6488\n",
      "Top 3 BERT Misclassified for reddit_chatGPT:\n",
      "  BERT_Err 1: True=Human, Pred=AI, Text='Henry died in a joust against the captain of his Scottish Guard, Gabriel, the Count of Montgomery.  ...'\n",
      "  BERT_Err 2: True=Human, Pred=AI, Text='Good question! [I answered this a few years back,](_URL_7_) but it was a fun topic so I'll pull that...'\n",
      "  BERT_Err 3: True=Human, Pred=AI, Text='Watergate is an incredibly interesting period of political history that I feel is greatly misunderst...'\n",
      "\n",
      "\n",
      "--- Processing Dev File: ./devset/reddit_cohere.jsonl ---\n",
      "\n",
      "Evaluating NaiveBayes_reddit_cohere...\n",
      "Results for NaiveBayes_reddit_cohere → Acc: 0.6002, Prec: 0.3686, Rec: 0.5369, F1: 0.4371\n",
      "Top 3 NB Misclassified for reddit_cohere:\n",
      "  NB_Err 1: True=AI, Pred=Human, Text='\n",
      "\n",
      "The English king Henry II was famously involved in a 1559 jousting accident in which he accidental...'\n",
      "  NB_Err 2: True=Human, Pred=AI, Text='In 1801, James Monroe and Robert R. Livingston (the R. also stood for Robert, oddly enough) were sen...'\n",
      "  NB_Err 3: True=Human, Pred=AI, Text='Good question! [I answered this a few years back,](_URL_7_) but it was a fun topic so I'll pull that...'\n",
      "\n",
      "Evaluating BERT_reddit_cohere...\n",
      "Results for BERT_reddit_cohere → Acc: 0.7405, Prec: 0.5339, Rec: 0.8066, F1: 0.6425\n",
      "Top 3 BERT Misclassified for reddit_cohere:\n",
      "  BERT_Err 1: True=Human, Pred=AI, Text='Henry died in a joust against the captain of his Scottish Guard, Gabriel, the Count of Montgomery.  ...'\n",
      "  BERT_Err 2: True=Human, Pred=AI, Text='Good question! [I answered this a few years back,](_URL_7_) but it was a fun topic so I'll pull that...'\n",
      "  BERT_Err 3: True=Human, Pred=AI, Text='Watergate is an incredibly interesting period of political history that I feel is greatly misunderst...'\n",
      "\n",
      "\n",
      "--- Overall Dev Set Performance Summary ---\n",
      "        model         dataset  accuracy  precision    recall        f1\n",
      "0  NaiveBayes   arxiv_chatGPT  0.531167   0.686627  0.114667  0.196515\n",
      "1        BERT   arxiv_chatGPT  0.533333   0.712766  0.111667  0.193084\n",
      "2  NaiveBayes    arxiv_cohere  0.657667   0.875397  0.367667  0.517840\n",
      "3        BERT    arxiv_cohere  0.647500   0.883117  0.340000  0.490975\n",
      "4  NaiveBayes  reddit_chatGPT  0.487667   0.482949  0.349333  0.405416\n",
      "5        BERT  reddit_chatGPT  0.665667   0.683260  0.617667  0.648810\n",
      "6  NaiveBayes   reddit_cohere  0.600237   0.368599  0.536885  0.437104\n",
      "7        BERT   reddit_cohere  0.740521   0.533912  0.806557  0.642507\n",
      "\n",
      "\n",
      "--- Average Performance Across Dev Subsets (per model) ---\n",
      "            accuracy  precision    recall        f1\n",
      "model                                              \n",
      "BERT        0.646755   0.703264  0.468973  0.493844\n",
      "NaiveBayes  0.569184   0.603393  0.342138  0.389219\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text_nb(text): # For Naive Bayes\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z0-9\\s]\", \"\", text)\n",
    "    toks = text.split()\n",
    "    return \" \".join(toks)\n",
    "\n",
    "def preprocess_text_bert_input(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"<[^>]+>\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "def load_dev_data_from_single_file(filepath):\n",
    "    texts = []\n",
    "    labels = []\n",
    "    processed_prompts = []\n",
    "    count = 0\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                data = json.loads(line)\n",
    "                human_text = data.get(\"human_text\")\n",
    "                machine_text = data.get(\"machine_text\")\n",
    "                prompt = data.get(\"prompt\", \"N/A\") # Get prompt if available\n",
    "\n",
    "                if human_text and isinstance(human_text, str) and len(human_text.strip()) > 0:\n",
    "                    texts.append(human_text)\n",
    "                    labels.append(0)\n",
    "                    processed_prompts.append(prompt)\n",
    "                \n",
    "                if machine_text and isinstance(machine_text, str) and len(machine_text.strip()) > 0:\n",
    "                    texts.append(machine_text)\n",
    "                    labels.append(1)\n",
    "                    processed_prompts.append(prompt)\n",
    "                count +=1\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Warning: Could not decode JSON from line in {filepath}: {line.strip()}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Error processing line {count} in {filepath}: {line.strip()} - {e}\")\n",
    "    return texts, labels, processed_prompts\n",
    "\n",
    "# Evaluation Function\n",
    "def evaluate_model_on_data(texts, labels, prompts, model_name_prefix, model_obj, \n",
    "                           is_bert=False, bert_tokenizer_obj=None, nb_vectorizer_obj=None):\n",
    "    print(f\"\\nEvaluating {model_name_prefix}...\")\n",
    "    \n",
    "    all_preds = []\n",
    "    \n",
    "    if is_bert:\n",
    "        # Preprocess texts for BERT input\n",
    "        processed_texts_for_bert = [preprocess_text_bert_input(t) for t in texts]\n",
    "        \n",
    "        # Using the passed model_obj\n",
    "        bert_pipeline = model_obj \n",
    "        id2label = bert_pipeline.model.config.id2label\n",
    "        label_to_int = {v: k for k, v in id2label.items()}\n",
    "        chunk_size = 64\n",
    "        for i in range(0, len(processed_texts_for_bert), chunk_size):\n",
    "            batch_texts = processed_texts_for_bert[i:i+chunk_size]\n",
    "            raw_batch_preds = bert_pipeline(batch_texts, truncation=True, padding=True, max_length=256)\n",
    "            batch_preds = [label_to_int[p['label']] for p in raw_batch_preds]\n",
    "            all_preds.extend(batch_preds)\n",
    "        preds = all_preds\n",
    "\n",
    "    else: # Naive Bayes\n",
    "        processed_texts_for_nb = [preprocess_text_nb(t) for t in texts]\n",
    "        X_dev_tfidf = nb_vectorizer_obj.transform(processed_texts_for_nb)\n",
    "        nb_classifier = model_obj\n",
    "        preds = nb_classifier.predict(X_dev_tfidf)\n",
    "\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\", pos_label=1, zero_division=0)\n",
    "    \n",
    "    misclassified_examples = []\n",
    "    for i in range(len(texts)):\n",
    "        if preds[i] != labels[i]:\n",
    "            misclassified_examples.append({\n",
    "                \"prompt\": prompts[i],\n",
    "                \"text\": texts[i],\n",
    "                \"true_label\": \"Human\" if labels[i] == 0 else \"AI\",\n",
    "                \"predicted_label\": \"Human\" if preds[i] == 0 else \"AI\"\n",
    "            })\n",
    "\n",
    "    print(f\"Results for {model_name_prefix} → Acc: {acc:.4f}, Prec: {prec:.4f}, Rec: {rec:.4f}, F1: {f1:.4f}\")\n",
    "    return {\"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1}, misclassified_examples\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    DEV_SET_ROOT_DIR = \"./devset/\"\n",
    "    NAIVE_BAYES_MODEL_PATH = \"baseline_saved_model/naive_bayes_model.joblib\" \n",
    "    NAIVE_BAYES_VECTORIZER_PATH = \"baseline_saved_model/tfidf_vectorizer.joblib\"\n",
    "    BERT_MODEL_DIR = \"./bert_ai_detector_final\"\n",
    "\n",
    "    # Load Naive Bayes Model and Vectorizer\n",
    "    nb_clf_loaded = None\n",
    "    tfidf_vec_loaded = None\n",
    "\n",
    "    nb_clf_loaded = joblib.load(NAIVE_BAYES_MODEL_PATH)\n",
    "    tfidf_vec_loaded = joblib.load(NAIVE_BAYES_VECTORIZER_PATH)\n",
    "    print(\"Naive Bayes model and vectorizer loaded successfully.\")\n",
    "\n",
    "    # Load BERT Model and Tokenizer\n",
    "    bert_pipeline_loaded = None\n",
    "    # Check if CUDA is available\n",
    "    device = 0 if torch.cuda.is_available() else -1\n",
    "    print(f\"Using device: {'cuda:0' if device == 0 else 'cpu'} for BERT.\")\n",
    "\n",
    "    # Load tokenizer and model first to ensure they exist\n",
    "    tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL_DIR)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(BERT_MODEL_DIR)\n",
    "        \n",
    "    bert_pipeline_loaded = pipeline(\n",
    "            \"text-classification\", \n",
    "            model=model, \n",
    "            tokenizer=tokenizer, \n",
    "            device=device\n",
    "    )\n",
    "\n",
    "    dev_filenames = [\n",
    "        \"arxiv_chatGPT.jsonl\",\n",
    "        \"arxiv_cohere.jsonl\",\n",
    "        \"reddit_chatGPT.jsonl\",\n",
    "        \"reddit_cohere.jsonl\"\n",
    "    ]\n",
    "\n",
    "    all_results_summary = [] # To store dicts for final DataFrame\n",
    "\n",
    "    for filename in dev_filenames:\n",
    "        filepath = os.path.join(DEV_SET_ROOT_DIR, filename)\n",
    "        dataset_short_name = filename.replace(\".jsonl\", \"\")\n",
    "        print(f\"\\n\\n--- Processing Dev File: {filepath} ---\")\n",
    "        texts, labels, prompts = load_dev_data_from_single_file(filepath)\n",
    "        \n",
    "        # Evaluate Naive Bayes\n",
    "        if nb_clf_loaded and tfidf_vec_loaded:\n",
    "            nb_metrics, nb_errors = evaluate_model_on_data(\n",
    "                texts, labels, prompts, \n",
    "                model_name_prefix=f\"NaiveBayes_{dataset_short_name}\", \n",
    "                model_obj=nb_clf_loaded, \n",
    "                is_bert=False, \n",
    "                nb_vectorizer_obj=tfidf_vec_loaded\n",
    "            )\n",
    "            nb_metrics['model'] = f\"NaiveBayes\" # For grouping\n",
    "            nb_metrics['dataset'] = dataset_short_name\n",
    "            all_results_summary.append(nb_metrics)\n",
    "            print(f\"Top 3 NB Misclassified for {dataset_short_name}:\")\n",
    "            for i, err in enumerate(nb_errors[:3]):\n",
    "                 print(f\"  NB_Err {i+1}: True={err['true_label']}, Pred={err['predicted_label']}, Text='{err['text'][:100]}...'\")\n",
    "\n",
    "        if bert_pipeline_loaded:\n",
    "            bert_metrics, bert_errors = evaluate_model_on_data(\n",
    "                texts, labels, prompts,\n",
    "                model_name_prefix=f\"BERT_{dataset_short_name}\", \n",
    "                model_obj=bert_pipeline_loaded, \n",
    "                is_bert=True\n",
    "            )\n",
    "            bert_metrics['model'] = f\"BERT\" # For grouping\n",
    "            bert_metrics['dataset'] = dataset_short_name\n",
    "            all_results_summary.append(bert_metrics)\n",
    "            print(f\"Top 3 BERT Misclassified for {dataset_short_name}:\")\n",
    "            for i, err in enumerate(bert_errors[:3]):\n",
    "                 print(f\"  BERT_Err {i+1}: True={err['true_label']}, Pred={err['predicted_label']}, Text='{err['text'][:100]}...'\")\n",
    "\n",
    "\n",
    "    # Print Results Table\n",
    "    if all_results_summary:\n",
    "        results_df = pd.DataFrame(all_results_summary)\n",
    "        print(\"\\n\\n--- Overall Dev Set Performance Summary ---\")\n",
    "        print(results_df[['model', 'dataset', 'accuracy', 'precision', 'recall', 'f1']])\n",
    "        print(\"\\n\\n--- Average Performance Across Dev Subsets (per model) ---\")\n",
    "        for col in ['accuracy', 'precision', 'recall', 'f1']:\n",
    "            results_df[col] = pd.to_numeric(results_df[col], errors='coerce')\n",
    "        avg_performance = results_df.groupby('model')[['accuracy', 'precision', 'recall', 'f1']].mean()\n",
    "        print(avg_performance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
